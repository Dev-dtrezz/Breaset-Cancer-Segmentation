{"cells":[{"cell_type":"code","execution_count":1,"id":"9b2d14f3-9267-4cb9-87a2-69a70614c1ed","metadata":{"executionInfo":{"elapsed":3294,"status":"ok","timestamp":1717169057873,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"9b2d14f3-9267-4cb9-87a2-69a70614c1ed"},"outputs":[],"source":["import torch\n","import torchvision.transforms as transforms\n","import os\n","import torch.nn.functional as F\n","# 학습 중 진행상황 print(진행률 막대)\n","import tqdm\n","import random\n","import cv2\n","from ipywidgets import interact\n","# 파일 및 디렉토리 작업\n","import shutil\n","import numpy as np\n","from PIL import Image\n","import re\n","# 다차원 이미지 처리\n","import scipy.ndimage as ndimage\n","import matplotlib.pyplot as plt\n","# 파일경로 다루기\n","from pathlib import Path\n","from torch import nn\n","# 텐서를 감싸기\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, Dataset, random_split"]},{"cell_type":"markdown","id":"Ok5eZJfUKB-i","metadata":{"id":"Ok5eZJfUKB-i"},"source":["# 0. 0_환경세팅"]},{"cell_type":"code","execution_count":2,"id":"wb7JDxX-5bLJ","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717169057874,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"wb7JDxX-5bLJ"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"id":"jGXdJkgR5iNn","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717169057875,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"jGXdJkgR5iNn"},"outputs":[],"source":["# # zip압축해제\n","# !unzip '/content/drive/MyDrive/03.Breast Cancer Segmentation/02. Unet_Dataset.zip' -d '/content/02. Unet_Dataset/'"]},{"cell_type":"markdown","id":"1Xgxncg56H84","metadata":{"id":"1Xgxncg56H84"},"source":["# 1. 1_ 데이터셋 생성"]},{"cell_type":"code","execution_count":4,"id":"78c7ebe9-f242-49a0-9110-9982fdc82eee","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1717169057875,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"78c7ebe9-f242-49a0-9110-9982fdc82eee"},"outputs":[],"source":["# 데이터셋 클래스 정의\n","class BreastDatasets(Dataset):\n","    def __init__(self, img_dir, mask_dir, img_transform, mask_transform):\n","        self.img_dir = img_dir\n","        self.mask_dir = mask_dir\n","        self.img_transform = img_transform\n","        self.mask_transform = mask_transform\n","        self.img_files = []\n","        self.mask_files = []\n","        self.seed = np.random.randint(2024)\n","\n","        for x in ['benign','malignant','normal']:\n","            file_img_dir = os.path.join(self.img_dir,x)\n","            file_mask_dir = os.path.join(self.mask_dir,x)\n","            for img_name in os.listdir(file_img_dir):\n","                if img_name.split('.')[-1] in ('png', 'jpg'):\n","                    self.img_files.append(os.path.join(file_img_dir, img_name))\n","                    self.mask_files.append(os.path.join(file_mask_dir, img_name))\n","\n","    def __len__(self):\n","        return len(self.img_files)\n","\n","    def __getitem__(self, i):\n","        img = Image.open(self.img_files[i]).convert('RGB')\n","        if self.img_transform is not None:\n","            random.seed(self.seed)\n","            img = self.img_transform(img)\n","\n","        mask = Image.open(self.mask_files[i]).convert('RGB')\n","        if self.mask_transform is not None:\n","            mask = self.mask_transform(mask)\n","\n","        return img, mask"]},{"cell_type":"code","execution_count":5,"id":"ec7486c7-2719-46e8-b615-a49477ecef74","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717169057876,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"ec7486c7-2719-46e8-b615-a49477ecef74"},"outputs":[],"source":["# # 데이터셋 클래스 정의\n","# class BreastDatasets(Dataset):\n","#     def __init__(self, img_dir, mask_dir, img_transform, mask_transform):\n","#         self.img_dir = img_dir\n","#         self.mask_dir = mask_dir\n","#         self.img_transform = img_transform\n","#         self.mask_transform = mask_transform\n","#         self.img_files = []\n","#         self.mask_files = []\n","#         self.seed = np.random.randint(2024)\n","\n","#         for img_name in os.listdir(self.img_dir):\n","#             if img_name.split('.')[-1] in ('png', 'jpg'):\n","#                 self.img_files.append(os.path.join(self.img_dir, img_name))\n","#                 self.mask_files.append(os.path.join(self.mask_dir, img_name))\n","\n","#     def __len__(self):\n","#         return len(self.img_files)\n","\n","#     def __getitem__(self, i):\n","#         img = Image.open(self.img_files[i])\n","#         if self.img_transform is not None:\n","#             random.seed(self.seed)\n","#             img = self.img_transform(img)\n","\n","#         mask = Image.open(self.mask_files[i]).convert('L') # 그레이스케일로 변환\n","#         if self.mask_transform is not None:\n","#             mask = self.mask_transform(mask)\n","\n","#         return img, mask"]},{"cell_type":"markdown","id":"01cc3a92-6d43-4f52-a52e-18384a5ede0b","metadata":{"id":"01cc3a92-6d43-4f52-a52e-18384a5ede0b"},"source":["# 2. 2_Unet 구현"]},{"cell_type":"code","execution_count":6,"id":"JRXmkh_QLk__","metadata":{"executionInfo":{"elapsed":506,"status":"ok","timestamp":1717169058373,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"JRXmkh_QLk__"},"outputs":[],"source":["# UNET 클래스로 구현\n","class UNet(nn.Module):\n","    # 클래스의 갯수 상속\n","    def __init__(self, num_classes):\n","        # nn.Module(부모) 클래스의 기능을 상속\n","        super(UNet, self).__init__()\n","        self.num_classes = num_classes\n","        # 3채널을 받아서 64로 반환(1번째 레이어)\n","        self.contracting_11 = self.conv_block(in_channels=3, out_channels=64)\n","        self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        # 64채널을 받아서 128채널로 반환(2번째 레이어)\n","        self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n","        self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        # 128채널을 받아서 256채널로 반환(3번째 레이어)\n","        self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n","        self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        # 64채널을 받아서 128채널로 반환(4번째 레이어)\n","        self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n","        self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        # 512채널을 받아서 1024채널로 반환(5번째 레이어)\n","        self.middle = self.conv_block(in_channels=512, out_channels=1024)\n","        self.expansive_11 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1, output_padding=1)\n","        self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n","        # 디코딩(확장)\n","        self.expansive_21 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n","        self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n","        # 3\n","        self.expansive_31 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1)\n","        self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n","        # 4\n","        self.expansive_41 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1)\n","        self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n","        # 결과물\n","        self.output = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1, stride=1)\n","\n","\n","    # n개의 채널을 받아서 n개의 채널로 내보내는 함수\n","    def conv_block(self, in_channels, out_channels):\n","        block = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n","                             nn.ReLU(),\n","                             nn.BatchNorm2d(num_features=out_channels),\n","                             nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n","                             nn.ReLU(),\n","                             nn.BatchNorm2d(num_features=out_channels))\n","        return block\n","\n","    def forward(self, X):\n","        # 컨볼루션 연산 -> 채널 상승\n","        contracting_11_out = self.contracting_11(X) # [-1, 64, 256, 256] : 배치 / 채널 / 이미지사이즈\n","        # 맥스풀링 -> 이미지 크기 감소\n","        contracting_12_out = self.contracting_12(contracting_11_out) #[-1, 64, 128, 128]\n","        # 2\n","        contracting_21_out = self.contracting_21(contracting_12_out) #[-1, 128, 128, 128]\n","        contracting_22_out = self.contracting_22(contracting_21_out) #[-1, 128, 64, 64]\n","        # 3\n","        contracting_31_out = self.contracting_31(contracting_22_out) #[-1, 256, 64, 64]\n","        contracting_32_out = self.contracting_32(contracting_31_out) #[-1, 256, 32, 32]\n","        # 4\n","        contracting_41_out = self.contracting_41(contracting_32_out) #[-1, 512, 32, 32]\n","        contracting_42_out = self.contracting_42(contracting_41_out) #[-1, 512, 16, 16]\n","        middle_out = self.middle(contracting_42_out) # [-1, 1024, 16, 16]\n","\n","    def forward(self, X):\n","        contracting_11_out = self.contracting_11(X) # [-1, 64, 256, 256]\n","        contracting_12_out = self.contracting_12(contracting_11_out) # [-1, 64, 128, 128]\n","        contracting_21_out = self.contracting_21(contracting_12_out) # [-1, 128, 128, 128]\n","        contracting_22_out = self.contracting_22(contracting_21_out) # [-1, 128, 64, 64]\n","        contracting_31_out = self.contracting_31(contracting_22_out) # [-1, 256, 64, 64]\n","        contracting_32_out = self.contracting_32(contracting_31_out) # [-1, 256, 32, 32]\n","        contracting_41_out = self.contracting_41(contracting_32_out) # [-1, 512, 32, 32]\n","        contracting_42_out = self.contracting_42(contracting_41_out) # [-1, 512, 16, 16]\n","        middle_out = self.middle(contracting_42_out) # [-1, 1024, 16, 16]\n","        expansive_11_out = self.expansive_11(middle_out) # [-1,512, 32, 32]\n","        expansive_12_out = self.expansive_12(torch.cat((expansive_11_out, contracting_41_out), dim=1)) # [-1, 1024,32,32] -> [-1, 512,32,32]\n","        expansive_21_out = self.expansive_21(expansive_12_out) # [-1, 256, 64, 64]\n","        expansive_22_out = self.expansive_22(torch.cat((expansive_21_out, contracting_31_out), dim=1)) # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n","        expansive_31_out = self.expansive_31(expansive_22_out) # [-1, 128, 128, 128]\n","        expansive_32_out = self.expansive_32(torch.cat((expansive_31_out, contracting_21_out), dim=1)) # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n","        expansive_41_out = self.expansive_41(expansive_32_out) # [-1, 64, 256, 256]\n","        expansive_42_out = self.expansive_42(torch.cat((expansive_41_out, contracting_11_out), dim=1)) # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n","        output_out = self.output(expansive_42_out) # [-1, num_classes, 256, 256]\n","        return output_out"]},{"cell_type":"code","execution_count":7,"id":"f7b3ca29-53d5-48ad-b46d-7e8f96dcf18f","metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1717169058373,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"f7b3ca29-53d5-48ad-b46d-7e8f96dcf18f"},"outputs":[],"source":["# # UNET 클래스로 구현\n","# class UNet(nn.Module):\n","#     # 클래스의 갯수 상속\n","#     def __init__(self, num_classes):\n","#         # nn.Module(부모) 클래스의 기능을 상속\n","#         super(UNet, self).__init__()\n","#         self.num_classes = num_classes\n","#         # 3채널을 받아서 64로 반환(1번째 레이어)\n","#         self.contracting_11 = self.conv_block(in_channels=3, out_channels=64)\n","#         self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n","#         # 64채널을 받아서 128채널로 반환(2번째 레이어)\n","#         self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n","#         self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n","#         # 128채널을 받아서 256채널로 반환(3번째 레이어)\n","#         self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n","#         self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n","#         # 64채널을 받아서 128채널로 반환(4번째 레이어)\n","#         self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n","#         self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n","#         # 512채널을 받아서 1024채널로 반환(5번째 레이어)\n","#         self.middle = self.conv_block(in_channels=512, out_channels=1024)\n","#         self.expansive_11 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1, output_padding=1)\n","#         self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n","#         # 디코딩(확장)\n","#         self.expansive_21 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n","#         self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n","#         # 3\n","#         self.expansive_31 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1)\n","#         self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n","#         # 4\n","#         self.expansive_41 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1)\n","#         self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n","#         # 결과물\n","#         self.output = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=3, stride=2)\n","\n","\n","#     # n개의 채널을 받아서 n개의 채널로 내보내는 함수\n","#     def conv_block(self, in_channels, out_channels):\n","#         block = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n","#                              nn.ReLU(),\n","#                              nn.BatchNorm2d(num_features=out_channels),\n","#                              nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n","#                              nn.ReLU(),\n","#                              nn.BatchNorm2d(num_features=out_channels))\n","#         return block\n","\n","#     def forward(self, X):\n","#         # 컨볼루션 연산 -> 채널 상승\n","#         contracting_11_out = self.contracting_11(X) # [-1, 64, 256, 256] : 배치 / 채널 / 이미지사이즈\n","#         # 맥스풀링 -> 이미지 크기 감소\n","#         contracting_12_out = self.contracting_12(contracting_11_out) #[-1, 64, 128, 128]\n","#         # 2\n","#         contracting_21_out = self.contracting_21(contracting_12_out) #[-1, 128, 128, 128]\n","#         contracting_22_out = self.contracting_22(contracting_21_out) #[-1, 128, 64, 64]\n","#         # 3\n","#         contracting_31_out = self.contracting_31(contracting_22_out) #[-1, 256, 64, 64]\n","#         contracting_32_out = self.contracting_32(contracting_31_out) #[-1, 256, 32, 32]\n","#         # 4\n","#         contracting_41_out = self.contracting_41(contracting_32_out) #[-1, 512, 32, 32]\n","#         contracting_42_out = self.contracting_42(contracting_41_out) #[-1, 512, 16, 16]\n","#         middle_out = self.middle(contracting_42_out) # [-1, 1024, 16, 16]\n","\n","#     def forward(self, X):\n","#         contracting_11_out = self.contracting_11(X) # [-1, 64, 256, 256]\n","#         contracting_12_out = self.contracting_12(contracting_11_out) # [-1, 64, 128, 128]\n","#         contracting_21_out = self.contracting_21(contracting_12_out) # [-1, 128, 128, 128]\n","#         contracting_22_out = self.contracting_22(contracting_21_out) # [-1, 128, 64, 64]\n","#         contracting_31_out = self.contracting_31(contracting_22_out) # [-1, 256, 64, 64]\n","#         contracting_32_out = self.contracting_32(contracting_31_out) # [-1, 256, 32, 32]\n","#         contracting_41_out = self.contracting_41(contracting_32_out) # [-1, 512, 32, 32]\n","#         contracting_42_out = self.contracting_42(contracting_41_out) # [-1, 512, 16, 16]\n","#         middle_out = self.middle(contracting_42_out) # [-1, 1024, 16, 16]\n","#         expansive_11_out = self.expansive_11(middle_out) # [-1,512, 32, 32]\n","#         expansive_12_out = self.expansive_12(torch.cat((expansive_11_out, contracting_41_out), dim=1)) # [-1, 1024,32,32] -> [-1, 512,32,32]\n","#         expansive_21_out = self.expansive_21(expansive_12_out) # [-1, 256, 64, 64]\n","#         expansive_22_out = self.expansive_22(torch.cat((expansive_21_out, contracting_31_out), dim=1)) # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n","#         expansive_31_out = self.expansive_31(expansive_22_out) # [-1, 128, 128, 128]\n","#         expansive_32_out = self.expansive_32(torch.cat((expansive_31_out, contracting_21_out), dim=1)) # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n","#         expansive_41_out = self.expansive_41(expansive_32_out) # [-1, 64, 256, 256]\n","#         expansive_42_out = self.expansive_42(torch.cat((expansive_41_out, contracting_11_out), dim=1)) # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n","#         output_out = self.output(expansive_42_out) # [-1, num_classes, 256, 256]\n","#         return output_out"]},{"cell_type":"markdown","id":"32886c8f-3e70-48f7-8b15-e1438ed48b83","metadata":{"id":"32886c8f-3e70-48f7-8b15-e1438ed48b83"},"source":["# 3. 3_Dice Score와 IoU 메트릭 함수 정의하기"]},{"cell_type":"code","execution_count":8,"id":"c0ad131e-a08f-4694-878c-9f19150fb037","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1717169058373,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"c0ad131e-a08f-4694-878c-9f19150fb037"},"outputs":[],"source":["# Dice coefficient: 두 개의 집합 간의 유사성을 측정하는 데 사용되는 통계적인 지표\n","# 2×∣A∩B∣ / ∣A∣+∣B∣\n","# 0에서 1까지의 값을 가지며, 1에 가까울수록 두 집합이 유사\n","# 1e-6: 0.000001\n","def dice_coeff(input, target, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n","    # assert 조건, \"에러 메세지\"\n","    assert input.size() == target.size()\n","    assert input.dim() == 3 or not reduce_batch_first\n","\n","    sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n","    inter = 2*(input * target).sum(dim=sum_dim)\n","    sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n","    # torch.where(): 조건에 따른 연산함수\n","    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n","\n","    dice = (inter + epsilon) / (sets_sum + epsilon)\n","    return dice.mean()\n","\n","\n","# IoU(Intersection over Union): 객체 검출 및 객체 분할과 같은 컴퓨터 비전 작업에서 사용되는 평가 지표\n","# 두 개의 영역 또는 객체가 주어졌을 때, IoU는 교집합을 합집합으로 나눈 것을 나타냄. 0에서 1사이의 값을 갖음\n","def iou(y_true, y_pred, epsilon: float = 1e-6):\n","    intersection = (y_true * y_pred).sum()\n","    union = y_true.sum() + y_pred.sum() - intersection\n","    return (intersection + epsilon) / (union + epsilon)"]},{"cell_type":"code","execution_count":9,"id":"12c04036-0151-4722-bcc6-698ce6eef1a6","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1717169058373,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"12c04036-0151-4722-bcc6-698ce6eef1a6"},"outputs":[],"source":["class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def find_latest_model_path(dir):\n","    model_paths = []\n","    epochs = []\n","    for path in Path(dir).glob('*.pth'):\n","        if 'epoch' not in path.stem:\n","            continue\n","        model_paths.append(path)\n","        parts = path.stem.split('_')\n","        epoch = int(parts[-1])\n","        epochs.append(epoch)\n","\n","    if len(epochs) > 0:\n","        epochs = np.array(epochs)\n","        max_idx = np.argmax(epochs)\n","        return model_paths[max_idx]\n","    else:\n","        return None\n","\n","# param_groups: 옵티마이저 객체 속성. 요소는 딕셔너리이며 매개변수 그룹에 대한 정보를 저장\n","def adjust_learning_rate(optimizer, epoch, lr):\n","    lr = lr * (0.1 ** (epoch // 30))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"]},{"cell_type":"markdown","id":"b6525d64-b37b-4829-841c-097bd29e0b06","metadata":{"id":"b6525d64-b37b-4829-841c-097bd29e0b06"},"source":["# 4. 4_train/valid 함수정의"]},{"cell_type":"code","execution_count":10,"id":"KNq1ZoEyXVm-","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717169058373,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"KNq1ZoEyXVm-"},"outputs":[],"source":["def visualize_images(input_img, target_mask, pred_mask, alpha):\n","    input_img = input_img.cpu().numpy().transpose(1, 2, 0)\n","    target_mask = target_mask.cpu().numpy().transpose(1, 2, 0)\n","    pred_mask = pred_mask.cpu().numpy().squeeze()\n","\n","    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n","    axs[0].imshow(input_img)\n","    axs[0].imshow(target_mask,alpha=alpha)\n","    axs[0].set_title('Origianl Mask')\n","    axs[0].axis('off')\n","\n","    axs[1].imshow(input_img)\n","    axs[1].imshow(pred_mask,alpha=alpha)\n","    axs[1].set_title('Predicted Mask')\n","    axs[1].axis('off')"]},{"cell_type":"code","execution_count":11,"id":"5484b463-ec17-4ab6-a493-2a7f65a1fc94","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"5484b463-ec17-4ab6-a493-2a7f65a1fc94"},"outputs":[],"source":["def train(train_loader, model, criterion, optimizer, valid_loader, model_dir, n_epoch, batch_size, lr, device):\n","    latest_model_path = find_latest_model_path(model_dir)\n","    best_model_path = os.path.join(*[model_dir, 'model_best.pth'])\n","\n","    if latest_model_path is not None:\n","        state = torch.load(latest_model_path)\n","        epoch = state['epoch']\n","        model.load_state_dict(state['model'])\n","        assert Path(best_model_path).exists() == True, f'best model path {best_model_path} does not exist!'\n","        best_state = torch.load(latest_model_path)\n","        min_val_los = best_state['valid_loss']\n","\n","        print(f'Restored model: {epoch}, Min validation loss: {min_val_los}')\n","        epoch += 1\n","        print(f'{epoch}')\n","    else:\n","        print('epoch: 0')\n","        epoch = 0\n","        min_val_los = 9999\n","\n","    valid_losses = []\n","\n","    for epoch in range(epoch, n_epoch):\n","        adjust_learning_rate(optimizer, epoch, lr)\n","        tq = tqdm.tqdm(total=(len(train_loader) * batch_size), dynamic_ncols=True)\n","        tq.set_description(f'Epoch {epoch}')\n","\n","        losses = AverageMeter()\n","        t_iou = 0\n","        t_dice = 0\n","\n","        model.train()\n","        for i, (input, target) in enumerate(train_loader):\n","            # Variable: 텐서를 대체하기 위해 사용되던 클래스(과거 버전의 텐서)\n","            input_var = Variable(input).to(device)\n","            target_var = Variable(target).to(device)\n","\n","            masks_pred = model(input_var)\n","            pred = torch.softmax(masks_pred, dim=1)\n","            target_mask = target_var.squeeze(1)\n","            # 예측 활성화 함수\n","            pred_classes = torch.argmax(pred, dim=1)\n","            # target_classes = torch.argmax(target_mask, dim=1).unsqueeze(1)\n","\n","            t_dice += dice_coeff(pred, target_mask)\n","            t_iou += iou(pred, target_mask)\n","\n","            masks_probs_flat = masks_pred.view(-1)\n","            true_masks_flat = target_var.view(-1)\n","\n","            loss = criterion(masks_probs_flat, true_masks_flat)\n","            losses.update(loss)\n","            tq.set_postfix(loss='{:.5f}'.format(losses.avg))\n","            tq.update(batch_size)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f'train miou : {t_iou/len(train_loader):.5f} train dice score : {t_dice/len(train_loader):.5f}')\n","        valid_metrics = valid(model, valid_loader, criterion)\n","        valid_loss = valid_metrics['valid_loss']\n","        valid_dice = valid_metrics['v_dice']\n","        valid_iou = valid_metrics['v_iou']\n","        valid_losses.append(valid_loss)\n","        print(f'valid_loss = {valid_loss:.5f}')\n","        print(f'valid miou : {valid_iou/len(valid_loader):.5f} valid dice score : {valid_dice/len(valid_loader):.5f}')\n","        tq.close()\n","\n","        visualize_images(input[epoch], target[epoch], pred[epoch], 0.4)\n","\n","        epoch_model_path = os.path.join(*[model_dir, f'model_epoch_{epoch}.pth'])\n","        torch.save({\n","            'model': model.state_dict(),\n","            'epoch': epoch,\n","            'valid_loss': valid_loss,\n","            'train_loss': losses.avg\n","        }, epoch_model_path)\n","\n","        if valid_loss < min_val_los:\n","            min_val_los = valid_loss\n","\n","            torch.save({\n","                'model': model.state_dict(),\n","                'epoch': epoch,\n","                'valid_loss': valid_loss,\n","                'train_loss': losses.avg\n","            }, best_model_path)"]},{"cell_type":"code","execution_count":12,"id":"73A2usczWuvl","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"73A2usczWuvl"},"outputs":[],"source":["# def train(train_loader, model, criterion, optimizer, valid_loader, model_dir, n_epoch, batch_size, lr, device):\n","#     latest_model_path = find_latest_model_path(model_dir)\n","#     best_model_path = os.path.join(*[model_dir, 'model_best.pth'])\n","\n","#     if latest_model_path is not None:\n","#         state = torch.load(latest_model_path)\n","#         epoch = state['epoch']\n","#         model.load_state_dict(state['model'])\n","#         assert Path(best_model_path).exists() == True, f'best model path {best_model_path} does not exist!'\n","#         best_state = torch.load(latest_model_path)\n","#         min_val_los = best_state['valid_loss']\n","\n","#         print(f'Restored model: {epoch}, Min validation loss: {min_val_los}')\n","#         epoch += 1\n","#         print(f'{epoch}')\n","#     else:\n","#         print('epoch: 0')\n","#         epoch = 0\n","#         min_val_los = 9999\n","\n","#     valid_losses = []\n","\n","#     for epoch in range(epoch, n_epoch):\n","#         adjust_learning_rate(optimizer, epoch, lr)\n","#         tq = tqdm.tqdm(total=(len(train_loader) * batch_size))\n","#         tq.set_description(f'Epoch {epoch}')\n","\n","#         losses = AverageMeter()\n","#         t_iou = 0\n","#         t_dice = 0\n","\n","#         model.train()\n","#         for i, (input, target) in enumerate(train_loader):\n","#             # Variable: 텐서를 대체하기 위해 사용되던 클래스(과거 버전의 텐서)\n","#             input_var = Variable(input).to(device)\n","#             target_var = Variable(target).to(device)\n","\n","#             masks_pred = model(input_var)\n","#             pred = F.sigmoid(masks_pred)\n","#             target_mask = target_var\n","\n","#             pred[pred>0.5] = 1\n","#             pred[pred<=0.5] = 0\n","#             target_mask[target_mask>0.5] = 1\n","#             target_mask[target_mask<=0.5] = 0\n","\n","#             t_dice += dice_coeff(pred, target_mask)\n","#             t_iou += iou(pred, target_mask)\n","\n","#             masks_probs_flat = masks_pred.view(-1)\n","#             true_masks_flat = target_var.view(-1)\n","\n","#             loss = criterion(masks_probs_flat, true_masks_flat)\n","#             losses.update(loss)\n","#             tq.set_postfix(loss='{:.5f}'.format(losses.avg))\n","#             tq.update(batch_size)\n","\n","#             optimizer.zero_grad()\n","#             loss.backward()\n","#             optimizer.step()\n","\n","#         print(f'train miou : {t_iou/len(train_loader):.5f} train dice score : {t_dice/len(train_loader):.5f}')\n","#         valid_metrics = valid(model, valid_loader, criterion)\n","#         valid_loss = valid_metrics['valid_loss']\n","#         valid_dice = valid_metrics['v_dice']\n","#         valid_iou = valid_metrics['v_iou']\n","#         valid_losses.append(valid_loss)\n","#         print(f'valid_loss = {valid_loss:.5f}')\n","#         print(f'valid miou : {valid_iou/len(valid_loader):.5f} valid dice score : {valid_dice/len(valid_loader):.5f}')\n","#         tq.close()\n","\n","#         epoch_model_path = os.path.join(*[model_dir, f'model_epoch_{epoch}.pth'])\n","#         torch.save({\n","#             'model': model.state_dict(),\n","#             'epoch': epoch,\n","#             'valid_loss': valid_loss,\n","#             'train_loss': losses.avg\n","#         }, epoch_model_path)\n","\n","#         if valid_loss < min_val_los:\n","#             min_val_los = valid_loss\n","\n","#             torch.save({\n","#                 'model': model.state_dict(),\n","#                 'epoch': epoch,\n","#                 'valid_loss': valid_loss,\n","#                 'train_loss': losses.avg\n","#             }, best_model_path)"]},{"cell_type":"code","execution_count":13,"id":"6118a7d5-e4c5-4a0b-b317-75d962ee5c45","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"6118a7d5-e4c5-4a0b-b317-75d962ee5c45"},"outputs":[],"source":["def valid(model, val_loader, criterion):\n","    losses = AverageMeter()\n","    v_iou = 0\n","    v_dice = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for i, (input, target) in enumerate(val_loader):\n","            input_var = Variable(input).to(device)\n","            target_var = Variable(target).to(device)\n","            output = model(input_var)\n","            loss = criterion(output, target_var)\n","            losses.update(loss.item(), input_var.size(0))\n","            pred = torch.argmax(output, dim=1)\n","            target_mask = target_var\n","\n","            # v_dice += dice_coeff(pred, target_mask)\n","            v_iou += iou(pred, target_mask)\n","\n","    return {'valid_loss': losses.avg, 'v_dice': v_dice, 'v_iou': v_iou}"]},{"cell_type":"code","execution_count":14,"id":"rk2nT5f6Gq2x","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"rk2nT5f6Gq2x"},"outputs":[],"source":["# def valid(model, val_loader, criterion):\n","#     losses = AverageMeter()\n","#     v_iou = 0\n","#     v_dice = 0\n","#     model.eval()\n","#     with torch.no_grad():\n","#         for i, (input, target) in enumerate(val_loader):\n","#             input_var = Variable(input).to(device)\n","#             target_var = Variable(target).to(device)\n","#             output = model(input_var)\n","#             loss = criterion(output, target_var)\n","#             losses.update(loss.item(), input_var.size(0))\n","#             pred = F.sigmoid(output)\n","#             target_mask = target_var\n","\n","#             pred[pred>0.5] = 1\n","#             pred[pred<=0.5] = 0\n","#             target_mask[target_mask>0.5] = 1\n","#             target_mask[target_mask<=0.5] = 0\n","\n","#             # v_dice += dice_coeff(pred, target_mask)\n","#             v_iou += iou(pred, target_mask)\n","\n","#     return {'valid_loss': losses.avg, 'v_dice': v_dice, 'v_iou': v_iou}"]},{"cell_type":"markdown","id":"2025468a-83db-4e57-b8f0-81c1f03a040d","metadata":{"id":"2025468a-83db-4e57-b8f0-81c1f03a040d"},"source":["# 5. 5_학습용 파라미터 정의"]},{"cell_type":"code","execution_count":15,"id":"330b8a96-d5b8-473e-ae72-d3bca0fa5484","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"330b8a96-d5b8-473e-ae72-d3bca0fa5484"},"outputs":[],"source":["# 모델 저장 폴더\n","model_dir = '/content/model_weights2'\n","os.makedirs(model_dir, exist_ok=True)\n","\n","# 데이터 저장 폴더\n","data_dir = '/content/02. Unet_Dataset'\n","DIR_IMG = os.path.join(data_dir, 'image')\n","DIR_MASK = os.path.join(data_dir, 'mask')\n","\n","# Device 할당\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","lr = 0.001\n","momentum = 0.9\n","weight_decay = 1e-4\n","batch_size = 4\n","num_workers = 8\n","n_epoch = 5"]},{"cell_type":"code","execution_count":16,"id":"e52479cd-fba0-4826-bd03-a2a4abde81de","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"e52479cd-fba0-4826-bd03-a2a4abde81de","outputId":"48046745-bf0f-4629-bf6b-1e186179b29a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla T4\n"]}],"source":["device\n","print(torch.cuda.get_device_name())"]},{"cell_type":"markdown","id":"s2luagxYNVaU","metadata":{"id":"s2luagxYNVaU"},"source":["# 6. 6_학습 사전 TEST"]},{"cell_type":"code","execution_count":17,"id":"DaAYMVyGGAil","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"DaAYMVyGGAil"},"outputs":[],"source":["# test_size = []\n","# for i in range(len(dataset)):\n","#     if dataset[i][0].shape != dataset[i][1].shape:\n","#         test_size.append(i)\n","#     else:\n","#         pass"]},{"cell_type":"code","execution_count":18,"id":"4hJQFoNiLCn0","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717169058374,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"4hJQFoNiLCn0"},"outputs":[],"source":["# test_size"]},{"cell_type":"code","execution_count":19,"id":"36GJ_VHlGr-6","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717169058375,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"36GJ_VHlGr-6"},"outputs":[],"source":["# def tensor_size(dataset, index):\n","#     print(dataset[index][0].shape)\n","#     print(dataset[index][1].shape)\n","# tensor_size(dataset, 647)"]},{"cell_type":"code","execution_count":20,"id":"5S9nyC1rFCKx","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1717169058375,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"5S9nyC1rFCKx"},"outputs":[],"source":["# dataiter = iter(train_loader)\n","# images, labels = next(dataiter)\n","# images, labels = images.to(device), labels.to(device)\n","# outputs = model(images)\n","\n","# outputs.shape"]},{"cell_type":"code","execution_count":21,"id":"obgpEiZlEa79","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1717169058375,"user":{"displayName":"육윤섭","userId":"08444879759633227373"},"user_tz":-540},"id":"obgpEiZlEa79"},"outputs":[],"source":["# num_epochs = 2\n","\n","# for epoch in range(num_epochs):\n","#     model.train()\n","#     train_loss = 0.0\n","\n","#     for images, masks in train_loader:\n","#         images, masks = images.to(device), masks.to(device)\n","\n","#         optimizer.zero_grad()\n","#         outputs = model(images)\n","#         loss = criterion(outputs, masks)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         train_loss += loss.item() * images.size(0)\n","\n","#     train_loss = train_loss / len(train_loader.dataset)\n","\n","#     print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}')"]},{"cell_type":"markdown","id":"pGZC7h-qOloE","metadata":{"id":"pGZC7h-qOloE"},"source":["# 7. 7_본 학습"]},{"cell_type":"code","execution_count":22,"id":"f2efab22-ecc4-49da-a80a-47d4f3cce819","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"f2efab22-ecc4-49da-a80a-47d4f3cce819","executionInfo":{"status":"error","timestamp":1717169100786,"user_tz":-540,"elapsed":42421,"user":{"displayName":"육윤섭","userId":"08444879759633227373"}},"outputId":"a750aa2f-98d2-42d0-e5f5-9c723053698a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0: 100%|██████████| 664/664 [00:39<00:00, 18.40it/s, loss=nan]"]},{"output_type":"stream","name":"stdout","text":["train miou : nan train dice score : nan\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-b0d5b638f7a2>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-71263de7bf2f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, valid_loader, model_dir, n_epoch, batch_size, lr, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train miou : {t_iou/len(train_loader):.5f} train dice score : {t_dice/len(train_loader):.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mvalid_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mvalid_dice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v_dice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-2b605c420ee7>\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(model, val_loader, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# v_dice += dice_coeff(pred, target_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mv_iou\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v_dice'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v_iou'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv_iou\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-ea2247d41482>\u001b[0m in \u001b[0;36miou\u001b[0;34m(y_true, y_pred, epsilon)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 두 개의 영역 또는 객체가 주어졌을 때, IoU는 교집합을 합집합으로 나눈 것을 나타냄. 0에서 1사이의 값을 갖음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mintersection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mintersection\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munion\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1"]}],"source":["# 모델 할당\n","model = UNet(num_classes=3)\n","\n","# 옵티마이저 정의\n","# weight_decay: L2정규화, 모델이 과적합되지 않도록 패널티 값\n","optimizer = torch.optim.SGD(model.parameters(), lr,\n","                            momentum=momentum, weight_decay=weight_decay)\n","\n","# 손실함수 정의\n","criterion = nn.CrossEntropyLoss().to(device)\n","\n","# transforms\n","channel_mean = [0.485, 0.456, 0.406]\n","channel_stds = [0.229, 0.224, 0.225]\n","train_tfms = transforms.Compose([transforms.ToTensor(), transforms.Resize(256),\n","                                 transforms.Normalize(channel_mean, channel_stds)])\n","val_tfms = transforms.Compose([transforms.ToTensor(), transforms.Resize(256),\n","                                 transforms.Normalize(channel_mean, channel_stds)])\n","mask_tfms = transforms.Compose([transforms.ToTensor(), transforms.Resize(256)])\n","\n","# 데이터셋\n","dataset = BreastDatasets(img_dir=DIR_IMG, img_transform=train_tfms, mask_dir=DIR_MASK,\n","                        mask_transform=mask_tfms)\n","train_size = int(0.85*len(dataset))\n","valid_size = len(dataset) - train_size\n","\n","# train/ val 데이터셋 분할\n","train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n","\n","# 데이터로더\n","train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=num_workers)\n","valid_loader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=num_workers)\n","\n","model.to(device)\n","\n","train(train_loader, model, criterion, optimizer, valid_loader, model_dir, n_epoch, batch_size, lr, device)"]},{"cell_type":"markdown","id":"EZH2Iw9ZRQgD","metadata":{"id":"EZH2Iw9ZRQgD"},"source":["# 7. test"]},{"cell_type":"code","execution_count":null,"id":"TE__frcFRSfi","metadata":{"id":"TE__frcFRSfi"},"outputs":[],"source":["model = UNet(num_classes=3)  # num_classes는 출력 클래스 수에 따라 조정\n","state = torch.load('/content/model_weights/model_best.pth')\n","model.load_state_dict(state['model'])\n","model.to(device)\n","model.eval()  # 모델을 평가 모드로 전환"]},{"cell_type":"code","execution_count":null,"id":"fDpwplP7UfGm","metadata":{"id":"fDpwplP7UfGm"},"outputs":[],"source":["state['train_loss']"]},{"cell_type":"code","execution_count":null,"id":"DN-65RS-RpFT","metadata":{"id":"DN-65RS-RpFT"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor()\n","])\n","\n","image = Image.open('/content/benign18.png')\n","plt.imshow(image)\n","image = transform(image).unsqueeze(0)  # 배치 차원을 추가"]},{"cell_type":"code","execution_count":null,"id":"Yz_V8bUeSdE6","metadata":{"id":"Yz_V8bUeSdE6"},"outputs":[],"source":["#예측수행\n","with torch.no_grad():\n","    image = image.to(device)  # GPU 사용 시\n","    output = model(image)\n","    output = torch.sigmoid(output)  # 바이너리 세그멘테이션의 경우\n","    output = (output > 0.5).float()  # 임계값 0.5로 이진화"]},{"cell_type":"code","execution_count":null,"id":"pjvWTYU2Sphb","metadata":{"id":"pjvWTYU2Sphb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.title('Input Image')\n","plt.imshow(image.squeeze().cpu().numpy().transpose(1, 2, 0))\n","\n","plt.subplot(1, 2, 2)\n","plt.title('Segmentation Output')\n","plt.imshow(output.squeeze().cpu().numpy().transpose(1, 2, 0))\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"DP-1Q5wETCjR","metadata":{"id":"DP-1Q5wETCjR"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":5}
